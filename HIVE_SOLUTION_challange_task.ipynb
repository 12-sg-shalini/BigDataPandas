{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522cc32-d4a2-46e3-aea2-4ae5d0758474",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scenario Based questions:\n",
    "Q1.Will the reducer work or not if you use “Limit 1” in any HiveQL query?\n",
    "\n",
    "Ans-2.I think Reducer will work, because as per Hive \n",
    "documentation -- Limit indicates the number of rows to be returned. The rows returned are chosen at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f793d4-2d6f-4593-853d-b3d3d58c5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2.Suppose I have installed Apache Hive on top of my Hadoop cluster using default metastore configuration. Then, what will \n",
    "happen if we have multiple clients trying to access Hive at the same time?\n",
    "\n",
    "Ans-2.The default metastore configuration allows only one Hive session to be \n",
    "opened at a time for accessing the metastore. Therefore, if multiple clients try to access the metastore at the same \n",
    "time, they will get an error. One has to use a standalone metastore, i.e. Local or remote metastore configuration in \n",
    "Apache Hive for allowing access to multiple clients concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c711517-8c62-4eb2-b4b8-9e8b42b2fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Suppose, I create a table that contains details of all the transactions done by the customers: CREATE TABLE transaction_details (cust_id INT, amount FLOAT, \n",
    "month STRING, country STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘,’ ;\n",
    "Now, after inserting 50,000 records in this table, I want to know the total revenue generated for each month. But, \n",
    "Hive is taking too much time in processing this query. How will you solve this problem and list the steps that I will be \n",
    "taking in order to do so?\n",
    "Ans-2.so,to solve this problems we have to partitioned it by partitioning the table by each month. but we can't partitioned thedata directly. so we create a \n",
    "partition table as:\n",
    "    CREATE TABLE partitioned_transaction (cust_id INT, amount FLOAT, country STRING) PARTITIONED BY (month STRING) ROW \n",
    "FORMAT DELIMITED FIELDS TERMINATED BY ‘,’ ;\n",
    "And we can enable dynamic partitioning in hive:\n",
    "    SET hive.exec.dynamic.partition = true;\n",
    "    SET hive.exec.dynamic.partition.mode = nonstrict;\n",
    "And transfer the data into it by writing this querry:\n",
    "INSERT OVERWRITE TABLE partitioned_transaction PARTITION (month) SELECT cust_id, amount, country, month FROM transaction_details;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b94e80-4bad-4ab9-a8e5-d68d04400a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How can you add a new partition for the month December in the above partitioned table?\n",
    "Ans-4. To add a new partition we have to write this querry: \n",
    "ALTER TABLE partitioned_transaction ADD PARTITION (month=’Dec’) LOCATION  ‘/partitioned_transaction’;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804971d-438e-4db7-948b-5ce0abab192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5.I am inserting data into a table based on partitions dynamically. But, I received an error – FAILED ERROR IN SEMANTIC \n",
    "ANALYSIS: Dynamic partition strict mode requires at least one static partition column. How will you remove this error?\n",
    "Ans-5.try both below properties:\n",
    "SET hive.exec.dynamic.partition = true;\n",
    "SET hive.exec.dynamic.partition.mode = nonstrict;\n",
    "And while writing insert statement for a partitioned table make sure that you specify the partition columns at the last \n",
    "in select clause. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66ca51-eb11-474f-b849-13fcbac1fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Suppose, I have a CSV file – ‘sample.csv’ present in ‘/temp’ directory with the following entries:\n",
    "id first_name last_name email gender ip_address\n",
    "How will you consume this CSV file into the Hive warehouse using built-in SerDe?\n",
    "Ans-6.SerDe stands for serialisation and deserialisation. so it convert unstructured data into a records that can process \n",
    "using hive. we can use this SerDe by using this command:\n",
    "    \n",
    "    CREATE EXTERNAL TABLE sample\n",
    "\n",
    "(id int, first_name string, \n",
    "\n",
    "last_name string, email string,\n",
    "\n",
    "gender string, ip_address string) \n",
    "\n",
    "ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.OpenCSVSerde’ \n",
    "\n",
    "STORED AS TEXTFILE LOCATION ‘/temp’;\n",
    "\n",
    "Now, we can perform any query on the table ‘sample’:\n",
    "\n",
    "SELECT first_name FROM sample WHERE gender = ‘male’;    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910ddde-79b7-41d0-85e6-6ace5f35ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Suppose, I have a lot of small CSV files present in the input directory in HDFS and I want to create a single Hive table corresponding to these files. The data in these files are in the format: {id, name, e-mail, country}. Now, as we know, Hadoop performance degrades when we use lots of small files.\n",
    "So, how will you solve this problem where we want to create a single Hive table for lots of small files without degrading the performance of the system?\n",
    "Ans-7. \n",
    "The steps that will be followed in doing so are as follows:\n",
    "Create a temporary table:\n",
    "CREATE TABLE temp_table (id INT, name STRING, e-mail STRING, country STRING)\n",
    "\n",
    "ROW FORMAT FIELDS DELIMITED TERMINATED BY ‘,’ STORED AS TEXTFILE;\n",
    "\n",
    "Load the data into temp_table:\n",
    "LOAD DATA INPATH ‘/input’ INTO TABLE temp_table;\n",
    "\n",
    "Create a table that will store data in SequenceFile format:\n",
    "CREATE TABLE sample_seqfile (id INT, name STRING, e-mail STRING, country STRING)\n",
    "\n",
    "ROW FORMAT FIELDS DELIMITED TERMINATED BY ‘,’ STORED AS SEQUENCEFILE;\n",
    "\n",
    "Transfer the data from the temporary table into the sample_seqfile table:\n",
    "INSERT OVERWRITE TABLE sample SELECT * FROM temp_table;\n",
    "\n",
    "so, the problems of small files doesn't degraded the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a72d2-f851-4195-839a-7ac61c2dadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8.LOAD DATA LOCAL INPATH ‘Home/country/state/’\n",
    "OVERWRITE INTO TABLE address;\n",
    "\n",
    "The following statement failed to execute. What can be the cause?\n",
    "Ans-8.The local inpath should contain a file and not a directory. The $env:HOME is a valid variable available in the \n",
    "hive environment.\n",
    "Is it possible to add 100 nodes when we already have 100 nodes in Hive? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01293f-f44d-4d85-a07a-dc26f92ff97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hive Practical questions:\n",
    "\n",
    "Hive Join operations\n",
    "\n",
    "Create a  table named CUSTOMERS(ID | NAME | AGE | ADDRESS   | SALARY)\n",
    "Create a Second  table ORDER(OID | DATE | CUSTOMER_ID | AMOUNT\n",
    ")\n",
    "\n",
    "Now perform different joins operations on top of these tables\n",
    "(Inner JOIN, LEFT OUTER JOIN ,RIGHT OUTER JOIN ,FULL OUTER JOIN)\n",
    "Ans-9.(a)INNER JOIN\n",
    "SELECT c.ID, c.NAME, c.AGE, o.AMOUNT \n",
    "FROM CUSTOMERS c JOIN ORDERS o \n",
    "ON (c.ID = o.CUSTOMER_ID);\n",
    "(B)LEFT OUTER JOIN\n",
    "SELECT c.ID, c.NAME, o.AMOUNT, o.DATE \n",
    "FROM CUSTOMERS c \n",
    "LEFT OUTER JOIN ORDERS o \n",
    "ON (c.ID = o.CUSTOMER_ID);\n",
    "(C)RIGHT OUTER JOIN\n",
    "SELECT c.ID, c.NAME, o.AMOUNT, o.DATE FROM CUSTOMERS c RIGHT OUTER JOIN ORDERS o ON (c.ID = o.CUSTOMER_ID);\n",
    "(D)FULL OUTER JOIN\n",
    " SELECT c.ID, c.NAME, o.AMOUNT, o.DATE \n",
    "FROM CUSTOMERS c \n",
    "FULL OUTER JOIN ORDERS o \n",
    "ON (c.ID = o.CUSTOMER_ID);\n",
    "\n",
    "BUILD A DATA PIPELINE WITH HIVE\n",
    "\n",
    "Download a data from the given location - \n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00360/\n",
    "\n",
    "1. Create a hive table as per given schema in your dataset \n",
    "2. try to place a data into table location\n",
    "3. Perform a select operation . \n",
    "4. Fetch the result of the select operation in your local as a csv file . \n",
    "5. Perform group by operation . \n",
    "7. Perform filter operation at least 5 kinds of filter examples . \n",
    "8. show and example of regex operation\n",
    "9. alter table operation \n",
    "10 . drop table operation\n",
    "12 . order by operation . \n",
    "13 . where clause operations you have to perform . \n",
    "14 . sorting operation you have to perform . \n",
    "15 . distinct operation you have to perform . \n",
    "16 . like an operation you have to perform . \n",
    "17 . union operation you have to perform . \n",
    "18 . table view operation you have to perform . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913d0d6c-0bb0-488b-ad0d-c56b0ab2852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hive operation with python Create a python application that connects to the Hive database for extracting data, creating \n",
    "sub tables for data processing, drops temporary tables.fetch rows to python itself into a list of tuples and mimic the \n",
    "join or filter operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b2064-0ee8-4fb9-9c38-1bb7a3d08909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8428a-813e-4dbc-b7fb-c40e404ec1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb27af7-ea2a-40e0-89f8-75226d2b5bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5e899-a7bb-452c-9265-de433e322ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
